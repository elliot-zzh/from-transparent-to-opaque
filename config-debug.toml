[general]
id = -1
model_name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
model_path = ""
hf_dataset_name = "ethangoh7086cmd/st-train-all"
hf_train_split = "openr171k"
im_end_token = "<｜end▁of▁sentence｜>"
eot_token = "<｜end▁of▁sentence｜>"
eoth_token = "</think>"
soft_thinking = true

[training]
num_epochs = 2
total_steps = 1000
log_interval = 1
save_interval = 256
batch_size = 1
max_train_length = 9999
max_sample_length = 7680
l_cache_length = 6144
concept_temperature = 0.1
concept_temperature_increase_step = 500
concept_temperature_max = 0.2
entropy_tao = 0.5
entropy_k = 9999
sample_num = 16
sample_topk = 20
sample_temperature = 0.7
sample_problem_batch = 2
sample_problem_sub_batch = 2
acc_check_only = false
train_gc_interval = 16
corr_reward = 2
gradient_accumulation_steps = 128
step = 1
clip_high = 0.3
clip_low = 0.2
lr = 1e-6
self_distillation_factor_pos = 1
self_distillation_factor_neg = 0.2
soft_embeds_train_start = 0

[model]
looping_depth = 0
hidden_layer_num = 20
depth_start_layer_num = 10
hidden_injection_layer = 0
pissa_niter = 32
lora_r = 16
lora_alpha = 32
double_gate = false
enable_injection_scale = true
enable_thinking = true
enable_swapping = true
