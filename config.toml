[general]
id = -1

[training]
num_epochs = 2
total_steps = 1000
log_interval = 1
save_interval = 256
batch_size = 1
max_train_length = 1024
max_sample_length = 768
l_cache_length = 600
sample_num = 24
sample_topk = 12
sample_temperature = 0.6
sample_problem_batch = 4
sample_problem_sub_batch = 1
acc_check_only = false
train_gc_interval = 12
corr_reward = 2
gradient_accumulation_steps = 32
step = 1
clip_high = 0.3
clip_low = 0.2
lr = 5e-6
vae_lr = 5e-6
gater_lr = 5e-6
gater_lr_min = 1e-6
gater_lr_decay_interval = 1000

[hidden_regularization]
hidden_regularization_rate = 0.6
hidden_dropout_rate = 0.02
hidden_reg_len_bonus_a = 20
hidden_reg_len_bonus_high = 10
hidden_updating_rate = 0.05

[gating_value]
gating_value_bonus = 0.2
gating_value_decay = 0.95
gating_value_lambda = 5
gating_bonus_update_step = 100

[model]
looping_depth = 0
hidden_layer_num = 20
depth_start_layer_num = 10

